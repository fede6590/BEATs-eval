{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTmnAISwqLDl"
      },
      "source": [
        "### DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dVO8fKb8hqnB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import os, logging, typing\n",
        "import sox\n",
        "import soundfile\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report            \n",
        "from utils import resample_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgJCSE0qEsY"
      },
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6SJU82ZpcD0"
      },
      "source": [
        "### Load Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "vzDF-7pahHYR",
        "outputId": "f7617abc-b489-4590-d43e-3e9a39e17c3b"
      },
      "outputs": [],
      "source": [
        "# from Tokenizers import TokenizersConfig, Tokenizers\n",
        "\n",
        "# def infer_token(audio_path, checkpoint_path):\n",
        "#     # load the tokenizer checkpoints\n",
        "#     checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "#     cfg = TokenizersConfig(checkpoint['cfg'])\n",
        "#     BEATs_tokenizer = Tokenizers(cfg)\n",
        "#     BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
        "#     BEATs_tokenizer.eval()\n",
        "\n",
        "#     audio_input_16khz = resample_audio(audio_path)\n",
        "#     labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=None)\n",
        "#     return labels\n",
        "\n",
        "# labels = infer_token('audios/ex_baby.wav', 'checkpoints/Tokenizer_iter3_plus_AS2M.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFbEF98kpzT3"
      },
      "source": [
        "### Load Pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CnWkqT4_puJF"
      },
      "outputs": [],
      "source": [
        "# from BEATs import BEATs, BEATsConfig\n",
        "\n",
        "# def infer_pretrained(audio_path, checkpoint_path):\n",
        "#     # load the pre-trained checkpoints\n",
        "#     checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "#     cfg = BEATsConfig(checkpoint['cfg'])\n",
        "#     BEATs_model = BEATs(cfg)\n",
        "#     BEATs_model.load_state_dict(checkpoint['model'])\n",
        "#     BEATs_model.eval()\n",
        "\n",
        "#     audio_input_16khz = resample_audio(audio_path)\n",
        "#     representation = BEATs_model.extract_features(audio_input_16khz, padding_mask=None)[0]\n",
        "#     return representation\n",
        "    \n",
        "# representation = infer_pretrained('audios/ex_baby.wav', 'checkpoints/BEATs_iter3_plus_AS2M.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGfc43zWpg9R"
      },
      "source": [
        "### Load Fine-tuned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "uXPYzItIhnvY",
        "outputId": "5756ce51-00c2-4768-c761-f12f50949b42"
      },
      "outputs": [],
      "source": [
        "from BEATs import BEATs, BEATsConfig\n",
        "\n",
        "def infer_finetuned(audio_path, checkpoint_path):\n",
        "    # load the fine-tuned checkpoints\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    cfg = BEATsConfig(checkpoint['cfg'])\n",
        "    BEATs_model = BEATs(cfg)\n",
        "    BEATs_model.load_state_dict(checkpoint['model'])\n",
        "    BEATs_model.eval()\n",
        "\n",
        "    audio_input_16khz = resample_audio(audio_path)\n",
        "    probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=None)[0]\n",
        "    return probs, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def topk_labels_prob(probs, checkpoint):\n",
        "    classes = pd.read_csv('labels/class_labels_indices.csv', index_col='index')\n",
        "\n",
        "    results = []\n",
        "    for (top_label_prob, top_label_idx) in zip(*probs.topk(k=1)):\n",
        "        top_label = [checkpoint['label_dict'][label_idx.item()] for label_idx in top_label_idx]\n",
        "        # Get classes from AudioSet class labels indices\n",
        "        tags = []\n",
        "        for c in top_label:\n",
        "            tag = classes[classes['mid'] == c]['display_name'].values[0]\n",
        "            tags.append(tag)\n",
        "        results.append([tags[0], top_label_prob.tolist()[0], tags[1], top_label_prob.tolist()[1]])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(audio_path, checkpoint_path):\n",
        "    probs, checkpoint = infer_finetuned(audio_path, checkpoint_path)\n",
        "    results = topk_labels_prob(probs, checkpoint)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare to previous results..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_id</th>\n",
              "      <th>Label</th>\n",
              "      <th>HTS_Labels</th>\n",
              "      <th>ResNet_Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0adb647e97de4fc8881e4c5359d3fb12.wav</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>first_5_seconds-0adb647e97de4fc8881e4c5359d3fb...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>next_5_seconds-0adb647e97de4fc8881e4c5359d3fb1...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46a32acc19f84410baa8c07ddaa6ac5a.wav</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>first_5_seconds-46a32acc19f84410baa8c07ddaa6ac...</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            audio_id  Label  HTS_Labels  \\\n",
              "0               0adb647e97de4fc8881e4c5359d3fb12.wav      0         NaN   \n",
              "1  first_5_seconds-0adb647e97de4fc8881e4c5359d3fb...      0         0.0   \n",
              "2  next_5_seconds-0adb647e97de4fc8881e4c5359d3fb1...      0         0.0   \n",
              "3               46a32acc19f84410baa8c07ddaa6ac5a.wav      3         NaN   \n",
              "4  first_5_seconds-46a32acc19f84410baa8c07ddaa6ac...      3         3.0   \n",
              "\n",
              "   ResNet_Labels  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              3  \n",
              "4              0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labeled_dataset = pd.read_csv('labels/labeled_dataset.csv', index_col=0)\n",
        "labeled_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_infer(folder:str, checkpoint_path:str, output = {}):\n",
        "    for name in os.listdir(folder):\n",
        "        path = os.path.join(folder, name)\n",
        "        if os.path.isfile(path) and path.endswith(\".wav\"):\n",
        "            filename = os.path.basename(path)\n",
        "            results = infer(path, checkpoint_path)\n",
        "            output[filename] = results[0]\n",
        "        elif os.path.isdir(path):\n",
        "            batch_infer(path, checkpoint_path, output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "LibsndfileError",
          "evalue": "Error opening '2023-07-18\\\\E4AAECA673A121689701159_1689701159000_2_2_0\\x00adb647e97de4fc8881e4c5359d3fb12.wav': System error.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pepe \u001b[39m=\u001b[39m infer(\u001b[39m'\u001b[39m\u001b[39m2023-07-18\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mE4AAECA673A121689701159_1689701159000_2_2_0\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39madb647e97de4fc8881e4c5359d3fb12.wav\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcheckpoints/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m pepe\n",
            "Cell \u001b[1;32mIn[6], line 2\u001b[0m, in \u001b[0;36minfer\u001b[1;34m(audio_path, checkpoint_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer\u001b[39m(audio_path, checkpoint_path):\n\u001b[1;32m----> 2\u001b[0m     probs, checkpoint \u001b[39m=\u001b[39m infer_finetuned(audio_path, checkpoint_path)\n\u001b[0;32m      3\u001b[0m     results \u001b[39m=\u001b[39m topk_labels_prob(probs, checkpoint)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36minfer_finetuned\u001b[1;34m(audio_path, checkpoint_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m BEATs_model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m BEATs_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 12\u001b[0m audio_input_16khz \u001b[39m=\u001b[39m resample_audio(audio_path)\n\u001b[0;32m     13\u001b[0m probs \u001b[39m=\u001b[39m BEATs_model\u001b[39m.\u001b[39mextract_features(audio_input_16khz, padding_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m probs, checkpoint\n",
            "File \u001b[1;32mc:\\Users\\Fede\\OneDrive\\Documentos\\TRS-MEDIA\\BEATs\\BEATs\\utils.py:9\u001b[0m, in \u001b[0;36mresample_audio\u001b[1;34m(input_path, target_sr)\u001b[0m\n\u001b[0;32m      7\u001b[0m torchaudio\u001b[39m.\u001b[39mset_audio_backend(\u001b[39m\"\u001b[39m\u001b[39msoundfile\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Load audio file from input_path\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m waveform, original_sr \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mload(input_path)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Resample to new sample rate (ouput as a Tensor)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m resampled_waveform \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mResample(original_sr, target_sr)(waveform)\n",
            "File \u001b[1;32mc:\\Users\\Fede\\miniconda3\\envs\\beats\\Lib\\site-packages\\torchaudio\\backend\\soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39m@_requires_soundfile\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m    141\u001b[0m     filepath: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[39mformat\u001b[39m: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, \u001b[39mint\u001b[39m]:\n\u001b[0;32m    148\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[39m    Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mwith\u001b[39;00m soundfile\u001b[39m.\u001b[39mSoundFile(filepath, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file_:\n\u001b[0;32m    222\u001b[0m         \u001b[39mif\u001b[39;00m file_\u001b[39m.\u001b[39mformat \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWAV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m normalize:\n\u001b[0;32m    223\u001b[0m             dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Fede\\miniconda3\\envs\\beats\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Fede\\miniconda3\\envs\\beats\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m file_ptr \u001b[39m==\u001b[39m _ffi\u001b[39m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[39m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mframes \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;31mLibsndfileError\u001b[0m: Error opening '2023-07-18\\\\E4AAECA673A121689701159_1689701159000_2_2_0\\x00adb647e97de4fc8881e4c5359d3fb12.wav': System error."
          ]
        }
      ],
      "source": [
        "pepe = infer('2023-07-18\\E4AAECA673A121689701159_1689701159000_2_2_0\\0adb647e97de4fc8881e4c5359d3fb12.wav', 'checkpoints/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt')\n",
        "pepe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INFERENCES - WARNING: the following command takes a while (11 min aprox.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to have all the audio files ready in the 'files' folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "beats_results = batch_infer('2023-07-18', 'checkpoints/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arranged_dict = [{**{'audio_id': key}, **{f'col_{i+1}': value[i] for i in range(4)}} for key, value in beats_results.items()]\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "df_beats_results = pd.DataFrame(arranged_dict)\n",
        "cols = {'col_1': 'BEATs_Labels','col_2': 'BEATs_Probs'}\n",
        "df_beats_results.rename(columns=cols, inplace=True)\n",
        "df_beats_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(\"Precisión (Accuracy):\", accuracy)\n",
        "\n",
        "    # Calcular la precisión del modelo\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    print(\"Precisión (Precision):\", precision)\n",
        "\n",
        "    # Calcular el recall del modelo\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    print(\"Recall:\", recall)\n",
        "\n",
        "    # Calcular la puntuación F1 del modelo\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(\"Puntuación F1:\", f1)\n",
        "\n",
        "    # Obtener la matriz de confusión\n",
        "    confusion = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Matriz de Confusión:\")\n",
        "    print(confusion)\n",
        "\n",
        "    # Obtener un informe de clasificación detallado\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jTmnAISwqLDl"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "beats",
      "language": "python",
      "name": "beats"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
