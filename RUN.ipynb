{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTmnAISwqLDl"
      },
      "source": [
        "### DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dVO8fKb8hqnB"
      },
      "outputs": [],
      "source": [
        "with open('libs.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            exec(f\"import {line}\")\n",
        "            \n",
        "from utils import resample_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgJCSE0qEsY"
      },
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6SJU82ZpcD0"
      },
      "source": [
        "### Load Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "vzDF-7pahHYR",
        "outputId": "f7617abc-b489-4590-d43e-3e9a39e17c3b"
      },
      "outputs": [],
      "source": [
        "# from Tokenizers import TokenizersConfig, Tokenizers\n",
        "\n",
        "# def infer_token(audio_path, checkpoint_path):\n",
        "#     # load the tokenizer checkpoints\n",
        "#     checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "#     cfg = TokenizersConfig(checkpoint['cfg'])\n",
        "#     BEATs_tokenizer = Tokenizers(cfg)\n",
        "#     BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
        "#     BEATs_tokenizer.eval()\n",
        "\n",
        "#     audio_input_16khz = resample_audio(audio_path)\n",
        "#     labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=None)\n",
        "#     return labels\n",
        "\n",
        "# labels = infer_token('audios/ex_baby.wav', 'checkpoints/Tokenizer_iter3_plus_AS2M.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFbEF98kpzT3"
      },
      "source": [
        "### Load Pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CnWkqT4_puJF"
      },
      "outputs": [],
      "source": [
        "# from BEATs import BEATs, BEATsConfig\n",
        "\n",
        "# def infer_pretrained(audio_path, checkpoint_path):\n",
        "#     # load the pre-trained checkpoints\n",
        "#     checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "#     cfg = BEATsConfig(checkpoint['cfg'])\n",
        "#     BEATs_model = BEATs(cfg)\n",
        "#     BEATs_model.load_state_dict(checkpoint['model'])\n",
        "#     BEATs_model.eval()\n",
        "\n",
        "#     audio_input_16khz = resample_audio(audio_path)\n",
        "#     representation = BEATs_model.extract_features(audio_input_16khz, padding_mask=None)[0]\n",
        "#     return representation\n",
        "    \n",
        "# representation = infer_pretrained('audios/ex_baby.wav', 'checkpoints/BEATs_iter3_plus_AS2M.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGfc43zWpg9R"
      },
      "source": [
        "### Load Fine-tuned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "uXPYzItIhnvY",
        "outputId": "5756ce51-00c2-4768-c761-f12f50949b42"
      },
      "outputs": [],
      "source": [
        "from BEATs import BEATs, BEATsConfig\n",
        "\n",
        "def infer_finetuned(audio_path, checkpoint_path):\n",
        "    # load the fine-tuned checkpoints\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    cfg = BEATsConfig(checkpoint['cfg'])\n",
        "    BEATs_model = BEATs(cfg)\n",
        "    BEATs_model.load_state_dict(checkpoint['model'])\n",
        "    BEATs_model.eval()\n",
        "\n",
        "    audio_input_16khz = resample_audio(audio_path)\n",
        "    probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=None)[0]\n",
        "    return probs, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def topk_labels_prob(probs, checkpoint):\n",
        "    classes = pd.read_csv('labels/class_labels_indices.csv', index_col='index')\n",
        "\n",
        "    results = []\n",
        "    for (top_label_prob, top_label_idx) in zip(*probs.topk(k=2)):\n",
        "        top_label = [checkpoint['label_dict'][label_idx.item()] for label_idx in top_label_idx]\n",
        "        # Get classes from AudioSet class labels indices\n",
        "        tags = []\n",
        "        for c in top_label:\n",
        "            tag = classes[classes['mid'] == c]['display_name'].values[0]\n",
        "            tags.append(tag)\n",
        "        results.append([tags[0], top_label_prob.tolist()[0], tags[1], top_label_prob.tolist()[1]])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(audio_path, checkpoint_path):\n",
        "    probs, checkpoint = infer_finetuned(audio_path, checkpoint_path)\n",
        "    results = topk_labels_prob(probs, checkpoint)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare to previous results..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_labeled = pd.read_csv('labels/all_labeled.csv', index_col='Unnamed: 0')\n",
        "all_labeled = all_labeled.drop(labels=['Unnamed: 0.1'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_infer(folder:str = 'files', checkpoint_path:str = 'checkpoints', output = {}):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        folder (str, optional): _description_. Defaults to 'files'.\n",
        "        checkpoint_path (str, optional): _description_. Defaults to 'checkpoints'.\n",
        "        output (dict, optional): _description_. Defaults to {}.\n",
        "\n",
        "    Returns:\n",
        "        dict: _description_\n",
        "    \"\"\"\n",
        "    for name in os.listdir(folder):\n",
        "        path = os.path.join(folder, name)\n",
        "        if os.path.isfile(path):\n",
        "            filename = os.path.basename(path)\n",
        "            results = infer(path, checkpoint_path)\n",
        "            output[filename] = results[0]\n",
        "        elif os.path.isdir(path):\n",
        "            batch_infer(path, checkpoint_path, output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INFERENCES - WARNING: the following command takes a while (11 min aprox.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# beats_results = batch_infer('files', 'checkpoints/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# arranged_dict = [{**{'audio_id': key}, **{f'col_{i+1}': value[i] for i in range(4)}} for key, value in beats_results.items()]\n",
        "\n",
        "# # Convert the list of dictionaries into a DataFrame\n",
        "# df_beats_results = pd.DataFrame(arranged_dict)\n",
        "# cols = {'col_1': 'first_label_beats','col_2': 'first_prob_beats', 'col_3': 'next_label_beats','col_4': 'next_prob_beats'}\n",
        "# df_beats_results.rename(columns=cols, inplace=True)\n",
        "# df_beats_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merged_inferences = pd.merge(all_labeled, df_beats_results, on='audio_id')\n",
        "# merged_inferences.head()                             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading inferences from .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merged_inferences.to_csv('merged_inferences.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_id</th>\n",
              "      <th>first_label_hts</th>\n",
              "      <th>first_prob_hts</th>\n",
              "      <th>next_label_hts</th>\n",
              "      <th>next_prob_hts</th>\n",
              "      <th>first_label_res</th>\n",
              "      <th>first_prob_res</th>\n",
              "      <th>next_label_res</th>\n",
              "      <th>next_prob_res</th>\n",
              "      <th>Label_audio_1</th>\n",
              "      <th>Label_audio_2</th>\n",
              "      <th>first_label_beats</th>\n",
              "      <th>first_prob_beats</th>\n",
              "      <th>next_label_beats</th>\n",
              "      <th>next_prob_beats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f7924b777e474520a516aa584a41d7e6.wav</td>\n",
              "      <td>mouse_click</td>\n",
              "      <td>2.319037</td>\n",
              "      <td>cow</td>\n",
              "      <td>2.214936</td>\n",
              "      <td>hen</td>\n",
              "      <td>-1.544079</td>\n",
              "      <td>mouse_click</td>\n",
              "      <td>-2.377246</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Speech</td>\n",
              "      <td>0.863339</td>\n",
              "      <td>Male speech, man speaking</td>\n",
              "      <td>0.312851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>903786b251994db3af3c454c9ddfc586.wav</td>\n",
              "      <td>hen</td>\n",
              "      <td>2.887828</td>\n",
              "      <td>dog</td>\n",
              "      <td>1.696776</td>\n",
              "      <td>breathing</td>\n",
              "      <td>-3.434196</td>\n",
              "      <td>dog</td>\n",
              "      <td>-2.485531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Speech</td>\n",
              "      <td>0.912175</td>\n",
              "      <td>Speech synthesizer</td>\n",
              "      <td>0.250158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c670303907b48d682468639f5be5c1c.wav</td>\n",
              "      <td>dog</td>\n",
              "      <td>3.303216</td>\n",
              "      <td>siren</td>\n",
              "      <td>1.861511</td>\n",
              "      <td>water_drops</td>\n",
              "      <td>-2.043841</td>\n",
              "      <td>coughing</td>\n",
              "      <td>-2.101418</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Speech</td>\n",
              "      <td>0.929904</td>\n",
              "      <td>Telephone</td>\n",
              "      <td>0.302890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7c2538cae6bb49548cf6f97cf4f6cbad.wav</td>\n",
              "      <td>siren</td>\n",
              "      <td>2.034104</td>\n",
              "      <td>keyboard_typing</td>\n",
              "      <td>1.913578</td>\n",
              "      <td>hen</td>\n",
              "      <td>0.325456</td>\n",
              "      <td>hen</td>\n",
              "      <td>-3.215177</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Speech</td>\n",
              "      <td>0.941915</td>\n",
              "      <td>Telephone</td>\n",
              "      <td>0.321044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92e8a42ea6834c82ad2e937c6f9c2edf.wav</td>\n",
              "      <td>dog</td>\n",
              "      <td>4.262393</td>\n",
              "      <td>chirping_birds</td>\n",
              "      <td>1.623316</td>\n",
              "      <td>water_drops</td>\n",
              "      <td>-1.874607</td>\n",
              "      <td>chirping_birds</td>\n",
              "      <td>-3.507891</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Speech</td>\n",
              "      <td>0.965017</td>\n",
              "      <td>Telephone</td>\n",
              "      <td>0.388490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               audio_id first_label_hts  first_prob_hts  \\\n",
              "0  f7924b777e474520a516aa584a41d7e6.wav     mouse_click        2.319037   \n",
              "1  903786b251994db3af3c454c9ddfc586.wav             hen        2.887828   \n",
              "2  0c670303907b48d682468639f5be5c1c.wav             dog        3.303216   \n",
              "3  7c2538cae6bb49548cf6f97cf4f6cbad.wav           siren        2.034104   \n",
              "4  92e8a42ea6834c82ad2e937c6f9c2edf.wav             dog        4.262393   \n",
              "\n",
              "    next_label_hts  next_prob_hts first_label_res  first_prob_res  \\\n",
              "0              cow       2.214936             hen       -1.544079   \n",
              "1              dog       1.696776       breathing       -3.434196   \n",
              "2            siren       1.861511     water_drops       -2.043841   \n",
              "3  keyboard_typing       1.913578             hen        0.325456   \n",
              "4   chirping_birds       1.623316     water_drops       -1.874607   \n",
              "\n",
              "   next_label_res  next_prob_res  Label_audio_1  Label_audio_2  \\\n",
              "0     mouse_click      -2.377246              0              0   \n",
              "1             dog      -2.485531              0              0   \n",
              "2        coughing      -2.101418              0              0   \n",
              "3             hen      -3.215177              0              0   \n",
              "4  chirping_birds      -3.507891              0              0   \n",
              "\n",
              "  first_label_beats  first_prob_beats           next_label_beats  \\\n",
              "0            Speech          0.863339  Male speech, man speaking   \n",
              "1            Speech          0.912175         Speech synthesizer   \n",
              "2            Speech          0.929904                  Telephone   \n",
              "3            Speech          0.941915                  Telephone   \n",
              "4            Speech          0.965017                  Telephone   \n",
              "\n",
              "   next_prob_beats  \n",
              "0         0.312851  \n",
              "1         0.250158  \n",
              "2         0.302890  \n",
              "3         0.321044  \n",
              "4         0.388490  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_inferences = pd.read_csv('merged_inferences.csv', index_col=0)\n",
        "merged_inferences.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión (Accuracy): 0.8238636363636364\n",
            "Precisión (Precision): 1.0\n",
            "Recall: 0.515625\n",
            "Puntuación F1: 0.6804123711340206\n",
            "Matriz de Confusión:\n",
            "[[112   0]\n",
            " [ 31  33]]\n",
            "Informe de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.88       112\n",
            "           1       1.00      0.52      0.68        64\n",
            "\n",
            "    accuracy                           0.82       176\n",
            "   macro avg       0.89      0.76      0.78       176\n",
            "weighted avg       0.86      0.82      0.81       176\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Preparing ground truth labels for metrics calculation\n",
        "ground_truth = merged_inferences['Label_audio_1'] + merged_inferences['Label_audio_2']\n",
        "y_true = [1 if entry != 0 else 0 for entry in ground_truth]\n",
        "\n",
        "# Preparing predicted labels for metrics calculation\n",
        "y_pred_1 = [1 if (('Baby' in entry) or entry == 'Cat') else 0 for entry in merged_inferences['first_label_beats']]\n",
        "y_pred_2 = [1 if (('Baby' in entry) or entry == 'Cat') else 0 for entry in merged_inferences['next_label_beats']]\n",
        "y_pred = [1 if entry != 0 else 0 for entry in [x + y for x, y in zip(y_pred_1, y_pred_2)]]\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(\"Precisión (Accuracy):\", accuracy)\n",
        "\n",
        "    # Calcular la precisión del modelo\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    print(\"Precisión (Precision):\", precision)\n",
        "\n",
        "    # Calcular el recall del modelo\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    print(\"Recall:\", recall)\n",
        "\n",
        "    # Calcular la puntuación F1 del modelo\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(\"Puntuación F1:\", f1)\n",
        "\n",
        "    # Obtener la matriz de confusión\n",
        "    confusion = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Matriz de Confusión:\")\n",
        "    print(confusion)\n",
        "\n",
        "    # Obtener un informe de clasificación detallado\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(report)\n",
        "\n",
        "metrics(y_true, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jTmnAISwqLDl"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
